---
title: Assignment 03 - AI Prompts
author:
  - name: Gavin Boss
    affiliations:
      - id: bu
        name: Boston University
        city: Boston
        state: MA
number-sections: true
date: '2025-09-20'
format:
  html:
    theme: cerulean
    toc: true
    toc-depth: 2
date-modified: today
date-format: long

---
# Appendix 1
::: {.callout-tip}
You're getting the same median salary across all ONET occupations because your `SALARY` column was overwritten with a constant value during data cleaning. Here's how to fix it step-by-step:
:::

:::{.callout-tip}
You're getting the same median salary across all ONET occupations because your `SALARY` column was overwritten with a constant value during data cleaning. Here's how to fix it step-by-step:

---

### âœ… 1. **Avoid Overwriting SALARY with a Constant**

In your current code:

```python
df = df.fillna({
  "SALARY_FROM": median_from,
  "SALARY_TO": median_to
})

df = df.withColumn("SALARY", (col("SALARY_FROM") + col("SALARY_TO")) / 2)
```

This fills missing `SALARY_FROM` and `SALARY_TO` with the same median, so any row missing salary data ends up with the same computed value â€” flattening the distribution.

---

### âœ… 2. **Use Conditional Logic to Preserve Original SALARY**

Replace the overwrite with this:

```python
df = df.withColumn("SALARY", when(
    col("SALARY").isNotNull() & (col("SALARY") > 0),
    col("SALARY")
).otherwise((col("SALARY_FROM") + col("SALARY_TO")) / 2))
```

This keeps the original `SALARY` if it's valid, and only computes it when missing.

---

### âœ… 3. **Double-Check Aggregation Logic**

Make sure you're grouping correctly and using `percentile_approx` with enough accuracy:

```python
agg_df = df.filter(
    col("SALARY").isNotNull() & (col("SALARY") > 0) &
    col("LOT_V6_SPECIALIZED_OCCUPATION_NAME").isNotNull() &
    (col("LOT_V6_SPECIALIZED_OCCUPATION_NAME") != "")
).groupBy("LOT_V6_SPECIALIZED_OCCUPATION_NAME") \
 .agg(
    expr("percentile_approx(SALARY, 0.5, 100)").alias("Median_Salary"),
    count("*").alias("Job_Postings")
).withColumnRenamed("LOT_V6_SPECIALIZED_OCCUPATION_NAME", "Occupation_Name")
```

If you still see duplicates, try increasing the accuracy:

```python
expr("percentile_approx(SALARY, 0.5, 1000)")
```

---

### âœ… 4. **Validate SALARY Distribution Before Aggregating**

Run this to confirm variation:

```python
df.select("SALARY").distinct().show(20)
```

If you see only one or two values, the issue is upstream in your fill logic.

---

Once you fix the conditional logic, your bubble chart will reflect real differences in median salary across occupations. Let me know if you want to filter out low-volume occupations or sort by salary for a cleaner visual.
:::

# Appendix 2
:::{.callout-tip}
how do I fix a plot in px.scatter that is stacked vertically
:::

:::{.callout-tip}
If your px.scatter plot is stacked vertically, it usually means your x-axis values are discrete or repeatedâ€”like integers or categoriesâ€”so all the points with the same x-value align in vertical lines. Here's how to fix it:

âœ… Add Jitter to the X-Axis
This spreads the points horizontally so they cluster more naturally:
import numpy as np

# Add jitter to your x-axis column
df["x_jittered"] = df["your_x_column"] + np.random.uniform(-0.3, 0.3, size=len(df))

# Use the jittered column in your plot
fig = px.scatter(
    df,
    x="x_jittered",
    y="your_y_column",
    ...
)

î·™î·š
This works especially well if your x-values are integers like years of experience.

ðŸ§  Why It Happens
- If x = 1, 2, 3..., all points with x=1 stack vertically.
- Jitter breaks that up by nudging each point slightly left or right.

ðŸ›  Optional Enhancements
- Add a trend line to show central tendency:
fig = px.scatter(..., trendline="ols")


- Use opacity to reveal dense areas:
fig.update_traces(opacity=0.6)


- Reduce marker size for better spacing:
fig.update_traces(marker=dict(size=6))



Let me know what your x-axis representsâ€”I can help you fine-tune the jitter or suggest alternatives like violin plots or density contours if clustering is key.
:::