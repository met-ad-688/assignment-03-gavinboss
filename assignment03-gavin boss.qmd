---
title: Assignment 03
author:
  - name: Gavin Boss
    affiliations:
      - id: bu
        name: Boston University
        city: Boston
        state: MA
number-sections: true
date: '2025-09-20'
format:
  ipynb:
  html:
    theme: cerulean
    toc: true
    toc-depth: 2
date-modified: today
date-format: long
execute:
  echo: false
  eval: true
  freeze: true
---
```{python}
from pyspark.sql import SparkSession
import pandas as pd
import plotly.express as px
import plotly.io as pio
import numpy as np
pio.renderers.default = "svg"
import re
import plotly.graph_objects as go
from pyspark.sql.functions import col, split, explode, regexp_replace, transform, when
from pyspark.sql import functions as F
from pyspark.sql.functions import col, monotonically_increasing_id

np.random.seed(42)

pio.renderers.default = "notebook"

# Initialize Spark Session
spark = SparkSession.builder.appName("LightcastData").getOrCreate()

# Load Data
df = spark.read.option("header", "true").option("inferSchema", "true").option("multiLine","true").option("escape", "\"").csv("data/lightcast_job_postings.csv")

# df.printSchema() # comment this line when rendering the submission
# df.show(5)
```

# Companies Table
```{python}
companies_df = df.select(
    col("company"),
    col("company_name"),
    col("company_raw"),
    col("company_is_staffing")
).distinct().withColumn("company_id", monotonically_increasing_id())

companies = companies_df.toPandas()
companies.drop(columns=["company"], inplace=True)
companies.to_csv("./output/companies.csv", index=False)
companies.head()
```

```{python}
salary_df = df.filter(col("SALARY").isNotNull() & (col("SALARY") > 0))
fig = px.histogram(salary_df.limit(5000).toPandas(), x="SALARY", nbins=50, title="Salary Distribution")
```

# Data Preparation (Clean Up Data)

```{python}
df = df.withColumn("SALARY_FROM", col("SALARY_FROM").cast("float")) \
       .withColumn("SALARY", col("SALARY").cast("float")) \
       .withColumn("MAX_YEARS_EXPERIENCE", col("MAX_YEARS_EXPERIENCE").cast("float")) \
       .withColumn("MIN_YEARS_EXPERIENCE", col("MIN_YEARS_EXPERIENCE").cast("float")) \
       .withColumn("SALARY_TO", col("SALARY_TO").cast("float")) \

def compute_median(sdf, col_name):
  q = sdf.approxQuantile(col_name, [0.5], 0.01)
  return q[0] if q else None

median_from = compute_median(df, "SALARY_FROM")
median_to = compute_median(df, "SALARY_TO")
median_salary =  compute_median(df, "SALARY")

print("Medians :", median_from, median_to, median_salary)

df = df.withColumn("SALARY", when(
    col("SALARY").isNotNull() & (col("SALARY") > 0),
    col("SALARY")
).otherwise((col("SALARY_FROM") + col("SALARY_TO")) / 2))

df = df.withColumn("SALARY", (col("SALARY_FROM") + col("SALARY_TO")) / 2)

export_cols = [
  "EDUCATION_LEVELS_NAME",
  "REMOTE_TYPE_NAME",
  "MAX_YEARS_EXPERIENCE",
  "SALARY",
  "LOT_V6_SPECIALIZED_OCCUPATION_NAME"
]
df_selected = df.select(*export_cols)

pdf = df_selected.toPandas()
pdf.to_csv("./data/lightcast_cleaned.csv", index=False)

print("Data cleaning complete. Rows retained:", len(pdf))
```

# Salary Distribution by Industry and Employment Type
```{python}

filtered_df = df.filter((df.SALARY_FROM.isNotNull()) & (df.SALARY_FROM > 0))

pdf = filtered_df.select("NAICS2_NAME", "EMPLOYMENT_TYPE_NAME", "SALARY_FROM").toPandas()

import plotly.express as px

fig = px.box(
    pdf,
    x="NAICS2_NAME",
    y="SALARY_FROM",
    color="EMPLOYMENT_TYPE_NAME",
    title="Salary Distribution by Industry and Employment Type",
    color_discrete_sequence=px.colors.qualitative.Set2
)

fig.update_layout(
    font_family="Arial",
    title_font_size=16,
    xaxis_title="Industry",
    yaxis_title="Salary",
    boxmode="group",
    width=1500,
    height=900,
    font=dict(
      family="Arial",
      size=12,
      color="black",
    ),
    title_font=dict(
      family="Arial",
      size=16,
      color="black",
    )
)

fig.show()
```

```{python}
import pandas as pd
#filter out missing or zero salary values
from pyspark.sql.functions import col
pdf = df.filter(col("SALARY") > 0).select("EMPLOYMENT_TYPE_NAME", "SALARY").toPandas()
pdf.head()
```

```{python}
# Filtering out missing or zero salary values
pdf = df.filter(df["SALARY"] > 0).select("EMPLOYMENT_TYPE_NAME", "SALARY").toPandas()

# Clean employment types names for better readability
pdf["EMPLOYMENT_TYPE_NAME"] = pdf["EMPLOYMENT_TYPE_NAME"].apply(
    lambda x: re.sub(r"[\x00-\x7F]+", "", x) if isinstance(x, str) else ""
)
# Computer median salary for sorting
median_salaries = pdf.groupby("EMPLOYMENT_TYPE_NAME")["SALARY"].median()

# Sort employment types based on median salary in descending order
sorted_employment_types = median_salaries.sort_values(ascending=False).index


pdf["EMPLOYMENT_TYPE_NAME"] = pd.Categorical(
  pdf["EMPLOYMENT_TYPE_NAME"],
  categories=sorted_employment_types,
  ordered=True
)

# Create Box Plot with horizontal grid lines
# fig = px.box(
# )
```
# 3 Salary Analysis by ONET Occupation Type (Bubble Chart)
--Appendix 1: Asked Copilot to help, as my aggregation was not workiong correctly, but it was because of a mix of the aggregation and the sorting that we had done in the saturday help session. AI prompts attached.
```{python}
from pyspark.sql.functions import col, expr, count
import plotly.express as px

valid_df = df.filter(
    col("SALARY").isNotNull() & (col("SALARY") > 0) &
    col("LOT_V6_SPECIALIZED_OCCUPATION_NAME").isNotNull()
)

valid_df = df.filter(
    col("SALARY").isNotNull() & (col("SALARY") > 0) &
    col("LOT_V6_SPECIALIZED_OCCUPATION_NAME").isNotNull() &
    (col("LOT_V6_SPECIALIZED_OCCUPATION_NAME") != "")
)

agg_df = df.filter(
    col("SALARY").isNotNull() & (col("SALARY") > 0) &
    col("LOT_V6_SPECIALIZED_OCCUPATION_NAME").isNotNull() &
    (col("LOT_V6_SPECIALIZED_OCCUPATION_NAME") != "")
).groupBy("LOT_V6_SPECIALIZED_OCCUPATION_NAME") \
 .agg(
    expr("percentile_approx(SALARY, 0.5, 100)").alias("Median_Salary"),
    count("*").alias("Job_Postings")
).withColumnRenamed("LOT_V6_SPECIALIZED_OCCUPATION_NAME", "Occupation_Name")

# Converting to pandas
bubble_pdf = agg_df.toPandas()

# Buble Chart
fig = px.scatter(
    bubble_pdf,
    x="Occupation_Name",
    y="Median_Salary",
    size="Job_Postings",
    color="Median_Salary",
    title="Salary Analysis by ONET Occupation Type",
    hover_name="Occupation_Name",
    size_max=60,
    template="plotly_white"
)

fig.update_layout(
    xaxis_title="Occupation Type",
    yaxis_title="Median Salary",
    width=1400,
    height=800,
    font=dict(family="Helvetica Neue", size=14),
    title_font=dict(size=28),
    margin=dict(l=40, r=40, t=80, b=120)
)

fig.show()
```

# 4 Salary by Education Level (Two Groups)

    Create two groups:
        Associate’s or lower (GED, Associate, No Education Listed)
        Bachelor’s (Bachelor’s degree)
        Master’s (Master’s degree)
        PhD (PhD, Doctorate, professional degree)
    Plot scatter plots for each group using, MAX_YEARS_EXPERIENCE (with jitter), Average_Salary, LOT_V6_SPECIALIZED_OCCUPATION_NAME
    After each graph, add a short explanation of key insights.

```{python}
from pyspark.sql.functions import col, when

lower_deg = ["Bachelor's", "Associate", "GED", "No Education Listed", "High school"]
higher_deg = ["Master's degree", "Ph.D. or professional degree"]

# Create education group column
df = df.withColumn(
    "EDU_GROUP",
    when(col("EDUCATION_LEVELS_NAME").rlike("|".join([f"(?i){deg}" for deg in lower_deg])), "Bachelor's or lower")
    .when(col("EDUCATION_LEVELS_NAME").rlike("|".join([f"(?i){deg}" for deg in higher_deg])), "Master's or PhD")
    .otherwise("Other")
)

# Cast columns properly
df = df.withColumn("MAX_YEARS_EXPERIENCE", col("MAX_YEARS_EXPERIENCE").cast("float"))
df = df.withColumn("Salary", col("Salary").cast("float"))

# Filter valid rows
df = df.filter(
    col("MAX_YEARS_EXPERIENCE").isNotNull() &
    col("Salary").isNotNull() &
    (col("MAX_YEARS_EXPERIENCE") > 0) &
    (col("Salary") > 0)
)

# Filter by education group
df_filtered = df.filter(col("EDU_GROUP").isin(["Bachelor's or lower", "Master's or PhD"]))
# Convert to pandas
df_pd = df_filtered.toPandas()
```
```{python}
import numpy as np

# Add jitter to experience values
df_pd["EXPERIENCE_JITTER"] = df_pd["MAX_YEARS_EXPERIENCE"] + np.random.uniform(-0.3, 0.3, size=len(df_pd))
```
```{python}
fig1 = px.scatter(
    df_pd,
    x="EXPERIENCE_JITTER",
    y="Salary",
    color="EDU_GROUP",
    hover_data=["LOT_V6_SPECIALIZED_OCCUPATION_NAME"],
    title="Experience vs Salary by Education Level",
    opacity=1,
    color_discrete_sequence=["#d62728", "#ff7f0e"],
    width=1000,
    height=600
)

fig1.update_traces(marker=dict(size=7, line=dict(width=1, color="black")))

fig1.update_layout(
    plot_bgcolor="#f9f9f9",
    paper_bgcolor="#fff5dc",
    font=dict(family="Segoe UI", size=14),
    title_font=dict(size=22),
    xaxis_title="Years of Experience",
    yaxis_title="Average Salary (USD)",
    legend_title="Education Group",
    hoverlabel=dict(bgcolor="white", font_size=13, font_family="Arial"),
    margin=dict(t=70, b=60, l=60, r=60),
    xaxis=dict(gridcolor="lightgray", tickmode="linear", dtick=1),
    yaxis=dict(gridcolor="lightgray")
)
# Needed to use iframe due to it being unable to render in preview with just show and not specifiying renderer
fig1.show()
fig1.write_html("output/q_1a_experience_vs_salary_by_education_level.html")
```

# 4 Salary by Education Level (Four Groups)

    Create two groups:
        Associate’s or lower (GED, Associate, No Education Listed)
        Bachelor’s (Bachelor’s degree)
        Master’s (Master’s degree)
        PhD (PhD, Doctorate, professional degree)
    Plot scatter plots for each group using, MAX_YEARS_EXPERIENCE (with jitter), Average_Salary, LOT_V6_SPECIALIZED_OCCUPATION_NAME
    After each graph, add a short explanation of key insights.

```{python}
from pyspark.sql.functions import col, when

lowest_deg = ["Associate", "GED", "No Education Listed", "High school"]
bach_deg = ["Bachelor's"]
mast_deg = ["Master's degree"]
phd_deg = ["Ph.D. or professional degree"]

# Create education group column
df = df.withColumn(
    "EDU_GROUP",
    when(col("EDUCATION_LEVELS_NAME").rlike("|".join([f"(?i){deg}" for deg in lowest_deg])), "Associate's or lower")
    .when(col("EDUCATION_LEVELS_NAME").rlike("|".join([f"(?i){deg}" for deg in bach_deg])), "Bachelor's")
    .when(col("EDUCATION_LEVELS_NAME").rlike("|".join([f"(?i){deg}" for deg in mast_deg])), "Master's")
    .when(col("EDUCATION_LEVELS_NAME").rlike("|".join([f"(?i){deg}" for deg in phd_deg])), "PhD")
    .otherwise("Other")
)

# Cast columns properly
df = df.withColumn("MAX_YEARS_EXPERIENCE", col("MAX_YEARS_EXPERIENCE").cast("float"))
df = df.withColumn("Salary", col("Salary").cast("float"))

# Filter valid rows
df = df.filter(
    col("MAX_YEARS_EXPERIENCE").isNotNull() &
    col("Salary").isNotNull() &
    (col("MAX_YEARS_EXPERIENCE") > 0) &
    (col("Salary") > 0)
)

# Filter by education group
df_filtered2 = df.filter(col("EDU_GROUP").isin(["Associate's or lower", "Bachelor's", "Master's", "PhD"]))

# Convert to pandas
df_pd2 = df_filtered2.toPandas()
```
#see appendix 2 -- asked ai to help me fix the data being in a straight line and it suggested the jitter.
```{python}
import numpy as np

# Add jitter to experience values
df_pd2["EXPERIENCE_JITTER"] = df_pd2["MAX_YEARS_EXPERIENCE"] + np.random.uniform(-0.3, 0.3, size=len(df_pd2))
```

```{python}
fig2 = px.scatter(
    df_pd2,
    x="EXPERIENCE_JITTER",  # use jittered x-axis
    y="Salary",
    color="EDU_GROUP",
    hover_data=["LOT_V6_SPECIALIZED_OCCUPATION_NAME"],
    title="Experience vs Salary by Education Level",
    opacity=1,
    color_discrete_sequence=["#ff7f0e", "#17becf", "#d62728", "#e377c2", "#1f77b4"],
    width=1000,
    height=600
)

fig2.update_traces(marker=dict(size=7, line=dict(width=1, color="black")))

fig2.update_layout(
    plot_bgcolor="#f9f9f9",
    paper_bgcolor="#fff5dc",
    font=dict(family="Segoe UI", size=14),
    title_font=dict(size=22),
    xaxis_title="Years of Experience",
    yaxis_title="Average Salary (USD)",
    legend_title="Education Group",
    hoverlabel=dict(bgcolor="white", font_size=13, font_family="Arial"),
    margin=dict(t=70, b=60, l=60, r=60),
    xaxis=dict(gridcolor="lightgray", tickmode="linear", dtick=1),
    yaxis=dict(gridcolor="lightgray")
)
# Needed to use iframe due to it being unable to render in preview with just show and not specifiying renderer
fig2.show()
fig2.write_html("output/q_1a_experience_vs_salary_by_education_level_4.html")
```